{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itamarbar-yossef/Desktop/ATLAS/articles_dataset.py:22: DtypeWarning: Columns (2,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_articles = pd.read_csv(articles_path)\n"
     ]
    }
   ],
   "source": [
    "from articles_dataset import load_articles\n",
    "\n",
    "# Companies used in our datatset, unrelated articles will be filtered out\n",
    "company_picks = {'Google': 'GOOGL', 'Delta': 'DAL', 'Lockheed Martin': 'LMT', 'Pfizer': 'PFE', \n",
    "                 'Qualcomm': 'QCOM', 'Netflix': 'NFLX', 'Baidu': 'BIDU', 'Biogen': 'BIIB',\n",
    "                 'AstraZeneca': 'AZN', 'First Solar': 'FSLR', 'Electronic Arts': 'EA', 'Activision': 'ATVI',\n",
    "                 'Nvidia': 'NVDA', 'Apple': 'AAPL', 'Advanced Micro Devices': 'AMD', 'GoPro': 'GPRO',\n",
    "                 'Alibaba': 'BABA', 'Tesla': 'TSLA', 'Amazon': 'AMZN'}\n",
    "\n",
    "articles = load_articles(company_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Samsung Profit Beats Estimates as Galaxy Smart...</td>\n",
       "      <td>Samsung Electronics Co., the world’s\\nsecond-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Security Officials Talked to City Police...</td>\n",
       "      <td>Apple Inc. (AAPL)  security officials met\\nwit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Looks to Overseas Growth to Stay on Top ...</td>\n",
       "      <td>Steve Jobs  built Apple Inc. into the\\nworld’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AZN</td>\n",
       "      <td>AstraZeneca Will Cut 400 U.S. Jobs Amid Generi...</td>\n",
       "      <td>AstraZeneca Plc (AZN) , the U.K.’s second-\\nbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple General Counsel Sewell Becomes Protector...</td>\n",
       "      <td>If  Steve Jobs  was the creative force\\nthat m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>PFE</td>\n",
       "      <td>Pfizer, J&amp;J Must Train U.S. Doctors on Safe Us...</td>\n",
       "      <td>Pfizer Inc. (PFE) ,  Johnson &amp; Johnson (JNJ)  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Google Shares' Downward Momentum Takes Time to...</td>\n",
       "      <td>The slide in  Google Inc. (GOOG)  that began\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Rodent Droppings ‘Too Numerous to Count’ Found...</td>\n",
       "      <td>Rodent droppings “too numerous to\\ncount” were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Record Streak for S&amp;P 500 Earnings May Rest Wi...</td>\n",
       "      <td>Investors counting on a record\\nstreak of high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Said to Add Foxconn’s Chimei as Supplier...</td>\n",
       "      <td>Apple Inc. (AAPL)  has agreed to add\\nFoxconn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6206 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date  Stock  \\\n",
       "0     2011-10-06 00:00:00 UTC   AAPL   \n",
       "1     2011-10-06 00:00:00 UTC   AAPL   \n",
       "2     2011-10-06 00:00:00 UTC   AAPL   \n",
       "3     2011-10-06 00:00:00 UTC    AZN   \n",
       "4     2011-10-06 00:00:00 UTC   AAPL   \n",
       "...                       ...    ...   \n",
       "6201  2011-04-19 00:00:00 UTC    PFE   \n",
       "6202  2011-04-19 00:00:00 UTC  GOOGL   \n",
       "6203  2011-04-19 00:00:00 UTC    DAL   \n",
       "6204  2011-04-19 00:00:00 UTC   AAPL   \n",
       "6205  2011-04-19 00:00:00 UTC   AAPL   \n",
       "\n",
       "                                          Article_title  \\\n",
       "0     Samsung Profit Beats Estimates as Galaxy Smart...   \n",
       "1     Apple Security Officials Talked to City Police...   \n",
       "2     Apple Looks to Overseas Growth to Stay on Top ...   \n",
       "3     AstraZeneca Will Cut 400 U.S. Jobs Amid Generi...   \n",
       "4     Apple General Counsel Sewell Becomes Protector...   \n",
       "...                                                 ...   \n",
       "6201  Pfizer, J&J Must Train U.S. Doctors on Safe Us...   \n",
       "6202  Google Shares' Downward Momentum Takes Time to...   \n",
       "6203  Rodent Droppings ‘Too Numerous to Count’ Found...   \n",
       "6204  Record Streak for S&P 500 Earnings May Rest Wi...   \n",
       "6205  Apple Said to Add Foxconn’s Chimei as Supplier...   \n",
       "\n",
       "                                                Article  \n",
       "0     Samsung Electronics Co., the world’s\\nsecond-l...  \n",
       "1     Apple Inc. (AAPL)  security officials met\\nwit...  \n",
       "2     Steve Jobs  built Apple Inc. into the\\nworld’s...  \n",
       "3     AstraZeneca Plc (AZN) , the U.K.’s second-\\nbi...  \n",
       "4     If  Steve Jobs  was the creative force\\nthat m...  \n",
       "...                                                 ...  \n",
       "6201  Pfizer Inc. (PFE) ,  Johnson & Johnson (JNJ)  ...  \n",
       "6202  The slide in  Google Inc. (GOOG)  that began\\n...  \n",
       "6203  Rodent droppings “too numerous to\\ncount” were...  \n",
       "6204  Investors counting on a record\\nstreak of high...  \n",
       "6205  Apple Inc. (AAPL)  has agreed to add\\nFoxconn ...  \n",
       "\n",
       "[6206 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>DAL</th>\n",
       "      <th>LMT</th>\n",
       "      <th>PFE</th>\n",
       "      <th>QCOM</th>\n",
       "      <th>NFLX</th>\n",
       "      <th>BIDU</th>\n",
       "      <th>BIIB</th>\n",
       "      <th>AZN</th>\n",
       "      <th>FSLR</th>\n",
       "      <th>EA</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMD</th>\n",
       "      <th>GPRO</th>\n",
       "      <th>BABA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1972-06-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972-06-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.846354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1972-06-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972-06-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12061</th>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>1162.920044</td>\n",
       "      <td>31.700001</td>\n",
       "      <td>350.329987</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>68.980003</td>\n",
       "      <td>362.989990</td>\n",
       "      <td>101.820000</td>\n",
       "      <td>304.940002</td>\n",
       "      <td>42.360001</td>\n",
       "      <td>37.619999</td>\n",
       "      <td>99.199997</td>\n",
       "      <td>57.720001</td>\n",
       "      <td>257.239990</td>\n",
       "      <td>258.440002</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>2.70</td>\n",
       "      <td>195.320007</td>\n",
       "      <td>528.159973</td>\n",
       "      <td>1955.489990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12062</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>1110.260010</td>\n",
       "      <td>29.549999</td>\n",
       "      <td>348.380005</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>66.589996</td>\n",
       "      <td>357.119995</td>\n",
       "      <td>97.629997</td>\n",
       "      <td>296.750000</td>\n",
       "      <td>42.470001</td>\n",
       "      <td>35.630001</td>\n",
       "      <td>95.370003</td>\n",
       "      <td>56.959999</td>\n",
       "      <td>252.729996</td>\n",
       "      <td>247.740005</td>\n",
       "      <td>46.580002</td>\n",
       "      <td>2.48</td>\n",
       "      <td>188.589996</td>\n",
       "      <td>514.359985</td>\n",
       "      <td>1900.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12063</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>1146.310059</td>\n",
       "      <td>28.670000</td>\n",
       "      <td>348.850006</td>\n",
       "      <td>32.669998</td>\n",
       "      <td>69.029999</td>\n",
       "      <td>370.959991</td>\n",
       "      <td>98.949997</td>\n",
       "      <td>316.130005</td>\n",
       "      <td>44.529999</td>\n",
       "      <td>36.060001</td>\n",
       "      <td>97.690002</td>\n",
       "      <td>58.470001</td>\n",
       "      <td>265.589996</td>\n",
       "      <td>254.809998</td>\n",
       "      <td>47.860001</td>\n",
       "      <td>2.64</td>\n",
       "      <td>191.270004</td>\n",
       "      <td>502.130005</td>\n",
       "      <td>1963.949951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12064</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1161.949951</td>\n",
       "      <td>28.530001</td>\n",
       "      <td>338.950012</td>\n",
       "      <td>32.639999</td>\n",
       "      <td>67.650002</td>\n",
       "      <td>375.500000</td>\n",
       "      <td>100.790001</td>\n",
       "      <td>316.380005</td>\n",
       "      <td>44.660000</td>\n",
       "      <td>36.060001</td>\n",
       "      <td>100.169998</td>\n",
       "      <td>59.480000</td>\n",
       "      <td>263.600006</td>\n",
       "      <td>254.289993</td>\n",
       "      <td>45.480000</td>\n",
       "      <td>2.62</td>\n",
       "      <td>194.479996</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>1949.719971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12065</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>1102.099976</td>\n",
       "      <td>23.870001</td>\n",
       "      <td>338.519989</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>65.900002</td>\n",
       "      <td>364.079987</td>\n",
       "      <td>97.680000</td>\n",
       "      <td>293.269989</td>\n",
       "      <td>43.779999</td>\n",
       "      <td>33.439999</td>\n",
       "      <td>97.529999</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>243.070007</td>\n",
       "      <td>240.910004</td>\n",
       "      <td>43.660000</td>\n",
       "      <td>2.49</td>\n",
       "      <td>187.559998</td>\n",
       "      <td>481.559998</td>\n",
       "      <td>1907.699951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12066 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        GOOGL        DAL         LMT        PFE       QCOM  \\\n",
       "0     1972-06-01          NaN        NaN         NaN   0.859375        NaN   \n",
       "1     1972-06-02          NaN        NaN         NaN   0.848958        NaN   \n",
       "2     1972-06-05          NaN        NaN         NaN   0.846354        NaN   \n",
       "3     1972-06-06          NaN        NaN         NaN   0.864583        NaN   \n",
       "4     1972-06-07          NaN        NaN         NaN   0.864583        NaN   \n",
       "...          ...          ...        ...         ...        ...        ...   \n",
       "12061 2020-03-26  1162.920044  31.700001  350.329987  31.750000  68.980003   \n",
       "12062 2020-03-27  1110.260010  29.549999  348.380005  30.900000  66.589996   \n",
       "12063 2020-03-30  1146.310059  28.670000  348.850006  32.669998  69.029999   \n",
       "12064 2020-03-31  1161.949951  28.530001  338.950012  32.639999  67.650002   \n",
       "12065 2020-04-01  1102.099976  23.870001  338.519989  31.750000  65.900002   \n",
       "\n",
       "             NFLX        BIDU        BIIB        AZN       FSLR          EA  \\\n",
       "0             NaN         NaN         NaN        NaN        NaN         NaN   \n",
       "1             NaN         NaN         NaN        NaN        NaN         NaN   \n",
       "2             NaN         NaN         NaN        NaN        NaN         NaN   \n",
       "3             NaN         NaN         NaN        NaN        NaN         NaN   \n",
       "4             NaN         NaN         NaN        NaN        NaN         NaN   \n",
       "...           ...         ...         ...        ...        ...         ...   \n",
       "12061  362.989990  101.820000  304.940002  42.360001  37.619999   99.199997   \n",
       "12062  357.119995   97.629997  296.750000  42.470001  35.630001   95.370003   \n",
       "12063  370.959991   98.949997  316.130005  44.529999  36.060001   97.690002   \n",
       "12064  375.500000  100.790001  316.380005  44.660000  36.060001  100.169998   \n",
       "12065  364.079987   97.680000  293.269989  43.779999  33.439999   97.529999   \n",
       "\n",
       "            ATVI        NVDA        AAPL        AMD  GPRO        BABA  \\\n",
       "0            NaN         NaN         NaN        NaN   NaN         NaN   \n",
       "1            NaN         NaN         NaN        NaN   NaN         NaN   \n",
       "2            NaN         NaN         NaN        NaN   NaN         NaN   \n",
       "3            NaN         NaN         NaN        NaN   NaN         NaN   \n",
       "4            NaN         NaN         NaN        NaN   NaN         NaN   \n",
       "...          ...         ...         ...        ...   ...         ...   \n",
       "12061  57.720001  257.239990  258.440002  47.500000  2.70  195.320007   \n",
       "12062  56.959999  252.729996  247.740005  46.580002  2.48  188.589996   \n",
       "12063  58.470001  265.589996  254.809998  47.860001  2.64  191.270004   \n",
       "12064  59.480000  263.600006  254.289993  45.480000  2.62  194.479996   \n",
       "12065  57.500000  243.070007  240.910004  43.660000  2.49  187.559998   \n",
       "\n",
       "             TSLA         AMZN  \n",
       "0             NaN          NaN  \n",
       "1             NaN          NaN  \n",
       "2             NaN          NaN  \n",
       "3             NaN          NaN  \n",
       "4             NaN          NaN  \n",
       "...           ...          ...  \n",
       "12061  528.159973  1955.489990  \n",
       "12062  514.359985  1900.099976  \n",
       "12063  502.130005  1963.949951  \n",
       "12064  524.000000  1949.719971  \n",
       "12065  481.559998  1907.699951  \n",
       "\n",
       "[12066 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from articles_dataset import load_stockprices\n",
    "stockdata = load_stockprices(list(company_picks.values()))\n",
    "stockdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Article</th>\n",
       "      <th>delta_week</th>\n",
       "      <th>delta_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Samsung Profit Beats Estimates as Galaxy Smart...</td>\n",
       "      <td>Samsung Electronics Co., the world’s\\nsecond-l...</td>\n",
       "      <td>4.437141</td>\n",
       "      <td>3.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Security Officials Talked to City Police...</td>\n",
       "      <td>Apple Inc. (AAPL)  security officials met\\nwit...</td>\n",
       "      <td>4.437141</td>\n",
       "      <td>3.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Looks to Overseas Growth to Stay on Top ...</td>\n",
       "      <td>Steve Jobs  built Apple Inc. into the\\nworld’s...</td>\n",
       "      <td>4.437141</td>\n",
       "      <td>3.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AZN</td>\n",
       "      <td>AstraZeneca Will Cut 400 U.S. Jobs Amid Generi...</td>\n",
       "      <td>AstraZeneca Plc (AZN) , the U.K.’s second-\\nbi...</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.985001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple General Counsel Sewell Becomes Protector...</td>\n",
       "      <td>If  Steve Jobs  was the creative force\\nthat m...</td>\n",
       "      <td>4.437141</td>\n",
       "      <td>3.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>PFE</td>\n",
       "      <td>Pfizer, J&amp;J Must Train U.S. Doctors on Safe Us...</td>\n",
       "      <td>Pfizer Inc. (PFE) ,  Johnson &amp; Johnson (JNJ)  ...</td>\n",
       "      <td>-0.340000</td>\n",
       "      <td>0.609999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Google Shares' Downward Momentum Takes Time to...</td>\n",
       "      <td>The slide in  Google Inc. (GOOG)  that began\\n...</td>\n",
       "      <td>5.650635</td>\n",
       "      <td>4.469452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Rodent Droppings ‘Too Numerous to Count’ Found...</td>\n",
       "      <td>Rodent droppings “too numerous to\\ncount” were...</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>1.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Record Streak for S&amp;P 500 Earnings May Rest Wi...</td>\n",
       "      <td>Investors counting on a record\\nstreak of high...</td>\n",
       "      <td>1.794289</td>\n",
       "      <td>-0.245712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Said to Add Foxconn’s Chimei as Supplier...</td>\n",
       "      <td>Apple Inc. (AAPL)  has agreed to add\\nFoxconn ...</td>\n",
       "      <td>1.794289</td>\n",
       "      <td>-0.245712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6206 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date  Stock  \\\n",
       "0     2011-10-06 00:00:00 UTC   AAPL   \n",
       "1     2011-10-06 00:00:00 UTC   AAPL   \n",
       "2     2011-10-06 00:00:00 UTC   AAPL   \n",
       "3     2011-10-06 00:00:00 UTC    AZN   \n",
       "4     2011-10-06 00:00:00 UTC   AAPL   \n",
       "...                       ...    ...   \n",
       "6201  2011-04-19 00:00:00 UTC    PFE   \n",
       "6202  2011-04-19 00:00:00 UTC  GOOGL   \n",
       "6203  2011-04-19 00:00:00 UTC    DAL   \n",
       "6204  2011-04-19 00:00:00 UTC   AAPL   \n",
       "6205  2011-04-19 00:00:00 UTC   AAPL   \n",
       "\n",
       "                                          Article_title  \\\n",
       "0     Samsung Profit Beats Estimates as Galaxy Smart...   \n",
       "1     Apple Security Officials Talked to City Police...   \n",
       "2     Apple Looks to Overseas Growth to Stay on Top ...   \n",
       "3     AstraZeneca Will Cut 400 U.S. Jobs Amid Generi...   \n",
       "4     Apple General Counsel Sewell Becomes Protector...   \n",
       "...                                                 ...   \n",
       "6201  Pfizer, J&J Must Train U.S. Doctors on Safe Us...   \n",
       "6202  Google Shares' Downward Momentum Takes Time to...   \n",
       "6203  Rodent Droppings ‘Too Numerous to Count’ Found...   \n",
       "6204  Record Streak for S&P 500 Earnings May Rest Wi...   \n",
       "6205  Apple Said to Add Foxconn’s Chimei as Supplier...   \n",
       "\n",
       "                                                Article  delta_week  \\\n",
       "0     Samsung Electronics Co., the world’s\\nsecond-l...    4.437141   \n",
       "1     Apple Inc. (AAPL)  security officials met\\nwit...    4.437141   \n",
       "2     Steve Jobs  built Apple Inc. into the\\nworld’s...    4.437141   \n",
       "3     AstraZeneca Plc (AZN) , the U.K.’s second-\\nbi...    0.510000   \n",
       "4     If  Steve Jobs  was the creative force\\nthat m...    4.437141   \n",
       "...                                                 ...         ...   \n",
       "6201  Pfizer Inc. (PFE) ,  Johnson & Johnson (JNJ)  ...   -0.340000   \n",
       "6202  The slide in  Google Inc. (GOOG)  that began\\n...    5.650635   \n",
       "6203  Rodent droppings “too numerous to\\ncount” were...    0.860000   \n",
       "6204  Investors counting on a record\\nstreak of high...    1.794289   \n",
       "6205  Apple Inc. (AAPL)  has agreed to add\\nFoxconn ...    1.794289   \n",
       "\n",
       "      delta_month  \n",
       "0        3.671429  \n",
       "1        3.671429  \n",
       "2        3.671429  \n",
       "3        0.985001  \n",
       "4        3.671429  \n",
       "...           ...  \n",
       "6201     0.609999  \n",
       "6202     4.469452  \n",
       "6203     1.880000  \n",
       "6204    -0.245712  \n",
       "6205    -0.245712  \n",
       "\n",
       "[6206 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from articles_dataset import add_deltas\n",
    "\n",
    "articles = add_deltas(articles, stockdata)\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Article</th>\n",
       "      <th>delta_week</th>\n",
       "      <th>delta_month</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Samsung Profit Beats Estimates as Galaxy Smart...</td>\n",
       "      <td>Samsung Electronics Co., the world’s\\nsecond-l...</td>\n",
       "      <td>4.437141</td>\n",
       "      <td>3.671429</td>\n",
       "      <td>The benchmark Kospi index gained 2.9 percent. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Security Officials Talked to City Police...</td>\n",
       "      <td>Apple Inc. (AAPL)  security officials met\\nwit...</td>\n",
       "      <td>4.437141</td>\n",
       "      <td>3.671429</td>\n",
       "      <td>“It’s common sense for us to work\\ntogether. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Looks to Overseas Growth to Stay on Top ...</td>\n",
       "      <td>Steve Jobs  built Apple Inc. into the\\nworld’s...</td>\n",
       "      <td>4.437141</td>\n",
       "      <td>3.671429</td>\n",
       "      <td>Hewlett-\\nPackard Co. is down 48 percent. Sale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AZN</td>\n",
       "      <td>AstraZeneca Will Cut 400 U.S. Jobs Amid Generi...</td>\n",
       "      <td>AstraZeneca Plc (AZN) , the U.K.’s second-\\nbi...</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.985001</td>\n",
       "      <td>AstraZeneca Plc (AZN) , the U.K.’s second-\\nbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-10-06 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple General Counsel Sewell Becomes Protector...</td>\n",
       "      <td>If  Steve Jobs  was the creative force\\nthat m...</td>\n",
       "      <td>4.437141</td>\n",
       "      <td>3.671429</td>\n",
       "      <td>Then came the iPhone. Jobs unveiled the iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>PFE</td>\n",
       "      <td>Pfizer, J&amp;J Must Train U.S. Doctors on Safe Us...</td>\n",
       "      <td>Pfizer Inc. (PFE) ,  Johnson &amp; Johnson (JNJ)  ...</td>\n",
       "      <td>-0.340000</td>\n",
       "      <td>0.609999</td>\n",
       "      <td>The risk-minimization program is the largest e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Google Shares' Downward Momentum Takes Time to...</td>\n",
       "      <td>The slide in  Google Inc. (GOOG)  that began\\n...</td>\n",
       "      <td>5.650635</td>\n",
       "      <td>4.469452</td>\n",
       "      <td>“Buying right after that initial fall, at leas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Rodent Droppings ‘Too Numerous to Count’ Found...</td>\n",
       "      <td>Rodent droppings “too numerous to\\ncount” were...</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>It was returned\\nto service within days after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Record Streak for S&amp;P 500 Earnings May Rest Wi...</td>\n",
       "      <td>Investors counting on a record\\nstreak of high...</td>\n",
       "      <td>1.794289</td>\n",
       "      <td>-0.245712</td>\n",
       "      <td>GE\\nreports earnings on April 21. Metrics  “Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>2011-04-19 00:00:00 UTC</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Said to Add Foxconn’s Chimei as Supplier...</td>\n",
       "      <td>Apple Inc. (AAPL)  has agreed to add\\nFoxconn ...</td>\n",
       "      <td>1.794289</td>\n",
       "      <td>-0.245712</td>\n",
       "      <td>Chimei Innolux will begin supplying the compon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6206 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date  Stock  \\\n",
       "0     2011-10-06 00:00:00 UTC   AAPL   \n",
       "1     2011-10-06 00:00:00 UTC   AAPL   \n",
       "2     2011-10-06 00:00:00 UTC   AAPL   \n",
       "3     2011-10-06 00:00:00 UTC    AZN   \n",
       "4     2011-10-06 00:00:00 UTC   AAPL   \n",
       "...                       ...    ...   \n",
       "6201  2011-04-19 00:00:00 UTC    PFE   \n",
       "6202  2011-04-19 00:00:00 UTC  GOOGL   \n",
       "6203  2011-04-19 00:00:00 UTC    DAL   \n",
       "6204  2011-04-19 00:00:00 UTC   AAPL   \n",
       "6205  2011-04-19 00:00:00 UTC   AAPL   \n",
       "\n",
       "                                          Article_title  \\\n",
       "0     Samsung Profit Beats Estimates as Galaxy Smart...   \n",
       "1     Apple Security Officials Talked to City Police...   \n",
       "2     Apple Looks to Overseas Growth to Stay on Top ...   \n",
       "3     AstraZeneca Will Cut 400 U.S. Jobs Amid Generi...   \n",
       "4     Apple General Counsel Sewell Becomes Protector...   \n",
       "...                                                 ...   \n",
       "6201  Pfizer, J&J Must Train U.S. Doctors on Safe Us...   \n",
       "6202  Google Shares' Downward Momentum Takes Time to...   \n",
       "6203  Rodent Droppings ‘Too Numerous to Count’ Found...   \n",
       "6204  Record Streak for S&P 500 Earnings May Rest Wi...   \n",
       "6205  Apple Said to Add Foxconn’s Chimei as Supplier...   \n",
       "\n",
       "                                                Article  delta_week  \\\n",
       "0     Samsung Electronics Co., the world’s\\nsecond-l...    4.437141   \n",
       "1     Apple Inc. (AAPL)  security officials met\\nwit...    4.437141   \n",
       "2     Steve Jobs  built Apple Inc. into the\\nworld’s...    4.437141   \n",
       "3     AstraZeneca Plc (AZN) , the U.K.’s second-\\nbi...    0.510000   \n",
       "4     If  Steve Jobs  was the creative force\\nthat m...    4.437141   \n",
       "...                                                 ...         ...   \n",
       "6201  Pfizer Inc. (PFE) ,  Johnson & Johnson (JNJ)  ...   -0.340000   \n",
       "6202  The slide in  Google Inc. (GOOG)  that began\\n...    5.650635   \n",
       "6203  Rodent droppings “too numerous to\\ncount” were...    0.860000   \n",
       "6204  Investors counting on a record\\nstreak of high...    1.794289   \n",
       "6205  Apple Inc. (AAPL)  has agreed to add\\nFoxconn ...    1.794289   \n",
       "\n",
       "      delta_month                                            Summary  \n",
       "0        3.671429  The benchmark Kospi index gained 2.9 percent. ...  \n",
       "1        3.671429  “It’s common sense for us to work\\ntogether. S...  \n",
       "2        3.671429  Hewlett-\\nPackard Co. is down 48 percent. Sale...  \n",
       "3        0.985001  AstraZeneca Plc (AZN) , the U.K.’s second-\\nbi...  \n",
       "4        3.671429  Then came the iPhone. Jobs unveiled the iPhone...  \n",
       "...           ...                                                ...  \n",
       "6201     0.609999  The risk-minimization program is the largest e...  \n",
       "6202     4.469452  “Buying right after that initial fall, at leas...  \n",
       "6203     1.880000  It was returned\\nto service within days after ...  \n",
       "6204    -0.245712  GE\\nreports earnings on April 21. Metrics  “Pe...  \n",
       "6205    -0.245712  Chimei Innolux will begin supplying the compon...  \n",
       "\n",
       "[6206 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from summarizer import get_summary_tfidf\n",
    "\n",
    "# Add a summarized column\n",
    "articles['Summary'] = articles['Article'].copy()\n",
    "articles['Summary'] = articles['Summary'].apply(lambda x: get_summary_tfidf([x], 4)) # summarize to 4 sentences\n",
    "articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuned BERT with Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(\"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\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = DistilBertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Start Training ------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m model = model.to(device)\n\u001b[32m     13\u001b[39m optim = get_optimizer(model, lr=\u001b[32m5e-4\u001b[39m, weight_decay=\u001b[32m1e-4\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m best_model_articles, stats = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m torch.save(best_model_articles.state_dict(), \u001b[33m\"\u001b[39m\u001b[33m./models/bert_model_articles.pth\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m plot_loss(stats)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ATLAS/bert.py:168\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(net, trn_loader, val_loader, optim, num_epoch, collect_cycle, patience, device, verbose)\u001b[39m\n\u001b[32m    165\u001b[39m inputs[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m] = inputs[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n\u001b[32m    166\u001b[39m labels = labels.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m scores = \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m loss = calculate_loss(scores, labels.float(), loss_fn)\n\u001b[32m    171\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ATLAS/bert.py:101\u001b[39m, in \u001b[36mBertClassifier.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids: torch.Tensor, attention_mask: torch.Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     bert_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistil_bert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m.last_hidden_state\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# use [CLS] token embedding\u001b[39;00m\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# embedding = bert_output[:, 0, :]\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# use mean pooling of non-mask layers\u001b[39;00m\n\u001b[32m    107\u001b[39m     mask = attention_mask.unsqueeze(-\u001b[32m1\u001b[39m).expand(bert_output.size()).float()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:797\u001b[39m, in \u001b[36mDistilBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    792\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_sdpa \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[32m    793\u001b[39m         attention_mask = _prepare_4d_attention_mask_for_sdpa(\n\u001b[32m    794\u001b[39m             attention_mask, embeddings.dtype, tgt_len=input_shape[\u001b[32m1\u001b[39m]\n\u001b[32m    795\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:550\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    542\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    543\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    544\u001b[39m         hidden_state,\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         output_attentions,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m hidden_state = layer_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:476\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[33;03mParameters:\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[33;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    475\u001b[39m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m sa_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[32m    485\u001b[39m     sa_output, sa_weights = sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nlp_proj/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:402\u001b[39m, in \u001b[36mDistilBertSdpaAttention.forward\u001b[39m\u001b[34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    399\u001b[39m     k = k.contiguous()\n\u001b[32m    400\u001b[39m     v = v.contiguous()\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m attn_output = unshape(attn_output)\n\u001b[32m    412\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.out_lin(attn_output)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# training on weekly data\n",
    "from bert import BertDatasetArticles, basic_collate_fn, BertClassifier, get_optimizer, train_model, plot_loss, get_performance, get_loss_fn\n",
    "\n",
    "dataset = BertDatasetArticles(articles, tokenizer)\n",
    "(train, val, test) = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1], generator=torch.Generator())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=64, collate_fn=basic_collate_fn, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=64, collate_fn=basic_collate_fn, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=64, collate_fn=basic_collate_fn, shuffle=False)\n",
    "\n",
    "model = BertClassifier(bert_model)\n",
    "model = model.to(device)\n",
    "optim = get_optimizer(model, lr=5e-4, weight_decay=1e-4)\n",
    "best_model_articles, stats = train_model(model, train_loader, val_loader, optim, 25, device=device)\n",
    "torch.save(best_model_articles.state_dict(), \"./models/bert_model_articles.pth\")\n",
    "plot_loss(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*get_performance(best_model_articles, get_loss_fn(), test_loader, device))  # maybe need to adjust threshold? try it out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
